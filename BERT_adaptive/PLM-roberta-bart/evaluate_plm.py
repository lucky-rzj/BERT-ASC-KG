# =======================================================================================
# æ¨¡å‹è¯„ä¼°å…¥å£----åŠ è½½æ¨¡å‹ + æ•°æ® + è°ƒç”¨æŒ‡æ ‡
# =======================================================================================
# åŠŸèƒ½ï¼šç”¨äºåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹å¹¶åœ¨æµ‹è¯•é›†ä¸Šè¿è¡Œé¢„æµ‹ï¼Œç„¶åè°ƒç”¨ evaluation.py ä¸­çš„æŒ‡æ ‡å‡½æ•°è¾“å‡ºæœ€ç»ˆæ€§èƒ½
# =======================================================================================
import json     
import logging  
import argparse   
import os    
import sys  
import random   
import numpy   
import  numpy as np 
import torch.nn as nn
import pandas as pd 
import torch    
from torch.utils.data.sampler import  WeightedRandomSampler    
from torch.utils.data import DataLoader, random_split, TensorDataset    
import torch.nn.functional as F   
import copy   
from  tqdm import tqdm   
from transformers import AdamW  
import torch.nn as nn


# --------------------- è‡ªå®šä¹‰æ¨¡å—å¯¼å…¥ --------------------------
from data_utils_plm import ABSADataset_absa_bert_semeval_json, ABSADataset_absa_bert_sentihood_json 
from evaluation import *  
from MyModel_adaptive_plm import PLM_ASC


# ------------------------- logger ------------------------------
logger = logging.getLogger()   
logger.setLevel(logging.INFO) 
logger.addHandler(logging.StreamHandler(sys.stdout))   


# -------------------- å®šä¹‰æŒ‡å¯¼ç±»ï¼Œç”¨äºæ¨¡å‹è¯„ä¼° --------------------
class Instructor:   
    def __init__(self, opt): 
        self.opt = opt   #å­˜å‚¨å‘½ä»¤è¡Œå‚æ•°
        
        # 1. åˆå§‹åŒ–æ¨¡å‹
        self.model = PLM_ASC.from_pretrained(opt.pretrained_model, num_labels=opt.label_dim, task_mode=opt.task_mode)
        self.model.to(self.opt.device)
        
        # 2. åˆå§‹åŒ–åˆ†è¯å™¨
        from transformers import AutoTokenizer
        #è‡ªåŠ¨è¯†åˆ« bart / roberta / 
        tokenizer = AutoTokenizer.from_pretrained(opt.pretrained_model, use_fast=False)

        # 3. æ ¹æ®æ•°æ®é›†çš„ç±»å‹ï¼ŒåŠ è½½æµ‹è¯•é›†    
        if self.opt.dataset=='semeval':  
            self.testset = ABSADataset_absa_bert_semeval_json(opt.dataset_file['test'], tokenizer, opt)
        else:
            self.testset = ABSADataset_absa_bert_sentihood_json(opt.dataset_file['test'], tokenizer, opt)
        logger.info(' test {}'.format( len(self.testset)))   
        
        if opt.device.type == 'cuda':   #è‹¥ä½¿ç”¨GPUï¼Œæ‰“å°æ˜¾å­˜ä½¿ç”¨æƒ…å†µ
            logger.info('cuda memory allocated: {}'.format(torch.cuda.memory_allocated(device=opt.device.index)))

        if torch.cuda.device_count() > 1:  #å¦‚æœæœ‰å¤šä¸ªGPUï¼Œä½¿ç”¨æ•°æ®å¹¶è¡Œ
            logger.info(f'Using {torch.cuda.device_count()} GPUs.')
            self.model = nn.DataParallel(self.model)
        self._print_args()   #æ‰“å°å‚æ•°ä¿¡æ¯

        
    # ----------------- è®¡ç®—å¯è®­ç»ƒå‚æ•°å’Œä¸å¯è®­ç»ƒå‚æ•° ---------------
    def _print_args(self):   
        n_trainable_params, n_nontrainable_params = 0, 0
        for p in self.model.parameters():    #éå†æ¨¡å‹å‚æ•°
            n_params = torch.prod(torch.tensor(p.shape))   
            if p.requires_grad:
                n_trainable_params += n_params
            else:
                n_nontrainable_params += n_params
        logger.info(
            'n_trainable_params: {0}, n_nontrainable_params: {1}'.format(n_trainable_params, n_nontrainable_params))
        logger.info('> training arguments:')
        for arg in vars(self.opt):
            logger.info('>>> {0}: {1}'.format(arg, getattr(self.opt, arg)))


    # ------------------------------ æ ¸å¿ƒè¯„ä¼°å‡½æ•° ------------------------------
    def _evaluate_acc_f1(self, data_loader):  
        n_correct, n_total = 0, 0   #æ­£ç¡®é¢„æµ‹æ•°ã€æ€»æ ·æœ¬æ•°
        t_targets_all, t_outputs_all = None, None   #å­˜å‚¨æ‰€æœ‰çœŸå®æ ‡ç­¾å’Œè¾“å‡º
        score = []   #å­˜å‚¨é¢„æµ‹åˆ†æ•°
        
        self.model.eval()   
        with torch.no_grad():   #å…³é—­æ¢¯åº¦è®¡ç®—
            for t_batch, t_sample_batched in enumerate(tqdm(data_loader)):  
                #å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
                t_sample_batched = [b.to(self.opt.device) for b in t_sample_batched]
                input_ids, attention_mask, labels = t_sample_batched

                logits = self.model(input_ids, attention_mask)     #æ¨¡å‹å‘å‰ä¼ æ’­ï¼Œè·å–è¾“å‡º
                score.append(F.softmax(logits, dim=-1).detach().cpu().numpy())   #å­˜å‚¨softmaxåçš„æ¦‚ç‡åˆ†æ•°
                
                n_correct += (torch.argmax(logits, -1) == labels).sum().item()
                n_total += len(logits)
                
                #æ‹¼æ¥æ‰€æœ‰æ‰¹æ¬¡çš„çœŸå®æ ‡ç­¾å’Œlogits
                if t_targets_all is None:   
                    t_targets_all = labels
                    t_outputs_all = logits
                else:
                    t_targets_all = torch.cat((t_targets_all, labels), dim=0)
                    t_outputs_all = torch.cat((t_outputs_all, logits), dim=0)
        #è¿”å›çœŸå®æ ‡ç­¾ã€é¢„æµ‹æ ‡ç­¾å’Œåˆ†æ•°
        return t_targets_all.cpu().numpy(), torch.argmax(t_outputs_all, -1).cpu().numpy(), np.concatenate(score, axis=0)

        

    # ====================================================================
    # âœ… RUN â€” ä¾æ¬¡åŠ è½½ seed æ¨¡å‹ + æ‰“å°æŒ‡æ ‡ + æ±‚å¹³å‡
    # =====================================================================
    def run(self): 
        #è½¬æ¢æµ‹è¯•é›†ä¸ºTensorDatasetæ ¼å¼
        testset = TensorDataset(torch.tensor([f['text_bert_indices'] for f in self.testset], dtype=torch.long),
                                 torch.tensor([f['input_mask'] for f in self.testset], dtype=torch.long),
                                 torch.tensor([f['label'] for f in self.testset], dtype=torch.long)
        )
        #æ„å»ºæµ‹è¯•é›†æ•°æ®åŠ è½½å™¨
        test_data_loader = DataLoader(dataset=testset, batch_size=self.opt.eval_batch_size, shuffle=False)  

        
        # --------------------------------------------------
        # ğŸ”§ ç»Ÿä¸€ SEEDSï¼ˆåº”ä¸ä½ è®­ç»ƒç«¯ä½¿ç”¨çš„å®Œå…¨ä¸€è‡´ï¼‰
        # --------------------------------------------------
        if self.opt.dataset == 'semeval':
            SEEDS = [42, 21, 7, 13, 87]
        else:
            SEEDS = [42, 101, 735, 2025, 12345]
            
        all_results = []    #ä¿å­˜æ¯ä¸ª seed çš„ç»“æœ


        # --------------------------------------------------
        # â­ ä¾æ¬¡åŠ è½½æ¯ä¸ª seed çš„æ¨¡å‹ + åšæµ‹è¯•
        # --------------------------------------------------
        for seed in SEEDS:
            #æŒ‰ç…§ä»»åŠ¡åˆ†ç±»åŠ è½½æœ€ä½³æ¨¡å‹å‚æ•°
            best_model_path = f"state_dict/{self.opt.dataset}/{self.opt.task_mode}/seed{seed}.bm"
            logger.info(f"\n============ Evaluating seed {seed} ============\n")
            #åŠ è½½æ¨¡å‹å‚æ•°
            state_dict = torch.load(best_model_path, map_location=self.opt.device)
            self.model.load_state_dict(state_dict)


            #-------------------------- æµ‹è¯•é›†ä¸Šè¯„ä¼°å¹¶è¾“å‡ºæŒ‡æ ‡ ---------------------
            self.model.eval()  
            y_true, y_pred, score = self._evaluate_acc_f1(test_data_loader)    #æµ‹è¯•é›†è¯„ä¼°æ¨¡å‹ï¼Œè·å–çœŸå®æ ‡ç­¾ã€é¢„æµ‹æ ‡ç­¾å’Œåˆ†æ•°
            if self.opt.dataset=='semeval':
                aspect_P, aspect_R, aspect_F = semeval_PRF(y_true, y_pred)
                sentiment_Acc_4_classes = semeval_Acc(y_true, y_pred, score, 4)
                sentiment_Acc_3_classes = semeval_Acc(y_true, y_pred, score, 3)
                sentiment_Acc_2_classes = semeval_Acc(y_true, y_pred, score, 2)

                # ----------- â­ æŒ‰ task_mode è¾“å‡ºæµ‹è¯•æŒ‡æ ‡ -----------
                if self.opt.task_mode == "implicit_aspect":
                    logger.info("******************** SemEval Test â€” Aspect Detection ********************")
                    logger.info('>> P: {:.4f} , R: {:.4f} , F: {:.4f}'.format(aspect_P, aspect_R, aspect_F))
                    logger.info("*************************************************************************")
                    #è®°å½•
                    all_results.append({
                        "P": aspect_P,
                        "R": aspect_R,
                        "F": aspect_F
                    })
                else:  
                    logger.info("******************** SemEval Test â€” Sentiment Classification ***********")
                    logger.info('>> 4-class Acc: {:.4f}'.format(sentiment_Acc_4_classes))
                    logger.info('>> 3-class Acc: {:.4f}'.format(sentiment_Acc_3_classes))
                    logger.info('>> 2-class Acc: {:.4f}'.format(sentiment_Acc_2_classes))
                    logger.info("*************************************************************************")
                    #è®°å½•
                    all_results.append({
                        "Acc4": sentiment_Acc_4_classes,
                        "Acc3": sentiment_Acc_3_classes,
                        "Acc2": sentiment_Acc_2_classes,
                    })
            else:
                aspect_strict_Acc = sentihood_strict_acc(y_true, y_pred)
                aspect_Macro_F1 = sentihood_macro_F1(y_true, y_pred)
                aspect_Macro_AUC, sentiment_Acc, sentiment_Macro_AUC = sentihood_AUC_Acc(y_true, score)

                # ----------- â­ æŒ‰ task_mode è¾“å‡ºæµ‹è¯•æŒ‡æ ‡ -----------
                if self.opt.task_mode == "implicit_aspect":
                    logger.info("******************** Sentihood Test â€” Aspect Detection *****************")
                    logger.info('>> aspect_strict_Acc: {:.4f}'.format(aspect_strict_Acc))
                    logger.info('>> aspect_Macro_F1:   {:.4f}'.format(aspect_Macro_F1))
                    logger.info('>> aspect_Macro_AUC:  {:.4f}'.format(aspect_Macro_AUC))
                    logger.info("*************************************************************************")
                    all_results.append({
                        "aspect_strict_Acc": aspect_strict_Acc,
                        "aspect_Macro_F1": aspect_Macro_F1,
                        "aspect_Macro_AUC": aspect_Macro_AUC,
                    })
                else:
                    logger.info("******************** Sentihood Test â€” Sentiment Classification *********")
                    logger.info('>> sentiment_Acc:      {:.4f}'.format(sentiment_Acc))
                    logger.info('>> sentiment_Macro_AUC: {:.4f}'.format(sentiment_Macro_AUC))
                    logger.info("*************************************************************************")
                    all_results.append({
                        "sentiment_Acc": sentiment_Acc,
                        "sentiment_Macro_AUC": sentiment_Macro_AUC,
                    })


        # --------------------------------------------------
        # â­â­ è¾“å‡º 5 æ¬¡çš„å¹³å‡ç»“æœ
        # --------------------------------------------------
        logger.info("\n==================== 5-SEED AVERAGE ====================")
        avg = {k: sum(r[k] for r in all_results) / len(all_results) for k in all_results[0]}
        if self.opt.dataset == 'semeval':
            if self.opt.task_mode == "implicit_aspect":
                logger.info(f"Avg P     = {avg['P']:.4f}")
                logger.info(f"Avg R     = {avg['R']:.4f}")
                logger.info(f"Avg F     = {avg['F']:.4f}")
            else:  
                logger.info(f"Avg Acc-4 = {avg['Acc4']:.4f}")
                logger.info(f"Avg Acc-3 = {avg['Acc3']:.4f}")
                logger.info(f"Avg Acc-2 = {avg['Acc2']:.4f}")
        else:
            if self.opt.task_mode == "implicit_aspect":
                logger.info(f"Avg strict_acc = {avg['aspect_strict_Acc']:.4f}")
                logger.info(f"Avg macro_F1   = {avg['aspect_Macro_F1']:.4f}")
                logger.info(f"Avg macro_AUC  = {avg['aspect_Macro_AUC']:.4f}")
            else:
                logger.info(f"Avg sent_Acc   = {avg['sentiment_Acc']:.4f}")
                logger.info(f"Avg sent_AUC   = {avg['sentiment_Macro_AUC']:.4f}")
        logger.info("=======================================================================")



def main():
    # Hyper Parameters
    parser = argparse.ArgumentParser()  
    parser.add_argument('--dataset', default='semeval', type=str,  choices=['semeval','sentihood'], help='semeval, sentihood', required=True)  
    parser.add_argument('--initializer', default='xavier_uniform_', type=str)    
    parser.add_argument('--learning_rate', default=3e-5, type=float, help='try 5e-5, 2e-5')  
    parser.add_argument('--dropout', default=0.1, type=float)  
    parser.add_argument('--l2reg', default=0.001, type=float) 
    parser.add_argument('--warmup_proportion', default=0.01, type=float)  
    parser.add_argument('--num_epoch', default=5, type=int, help='')    #è®­ç»ƒè½®æ•°
    parser.add_argument("--train_batch_size", default=32,type=int, help="Total batch size for training.")  #è®­ç»ƒçš„æ€»æ‰¹æ¬¡å¤§å°
    parser.add_argument("--eval_batch_size", default=64, type=int, help="Total batch size for eval.")    #è¯„ä¼°çš„æ€»æ‰¹æ¬¡å¤§å°
    parser.add_argument('--log_step', default=50, type=int)
    parser.add_argument('--max_seq_len', default=120, type=int)  #æ–‡æœ¬çš„æœ€å¤§åºåˆ—é•¿åº¦
    parser.add_argument('--label_dim', default=5, type=int)  
    parser.add_argument('--hops', default=3, type=int)
    parser.add_argument('--pretrained_model', default='bart-base', type=str)
    parser.add_argument('--save_model', default=0, type=int)    #ä¿å­˜æœ€ä½³æ¨¡å‹çš„è®¾ç½®
    parser.add_argument('--device', default='cuda', type=str, help='e.g. cuda:0')
    parser.add_argument('--seed', default=42, type=int, help='set seed for reproducibility')  #éšæœºç§å­
    parser.add_argument('--valset_ratio', default=0, type=float,
                        help='set ratio between 0 and 1 for validation support')    #éªŒè¯æ¯”ä¾‹ï¼ˆè®¾ç½®0åˆ°1ä¹‹é—´çš„æ¯”ä¾‹ä½œä¸ºéªŒè¯é›†æ”¯æŒï¼‰
    parser.add_argument('--task_mode',
                    default='sentiment_polarity',
                    type=str,
                    choices=['sentiment_polarity', 'implicit_aspect'],
                    help='æ§åˆ¶è‡ªé€‚åº”å±‚èåˆçš„ä»»åŠ¡åç½®')
    
    opt = parser.parse_args()

    
    if opt.dataset=='sentihood':  #æ ¹æ®æ•°æ®é›†è®¾ç½®æ ‡ç­¾ç»´åº¦ï¼ˆSentihoodä¸º3ç±»ï¼ŒSemEvalä¸º5ç±»ï¼‰
        opt.label_dim =3

        
    #è®¾ç½®éšæœºç§å­ä»¥ä¿è¯å¯å¤ç°æ€§
    if opt.seed is not None:
        random.seed(opt.seed)
        numpy.random.seed(opt.seed)
        torch.manual_seed(opt.seed)
        torch.cuda.manual_seed(opt.seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False

        
    #å®šä¹‰æ•°æ®é›†çš„æ–‡ä»¶è·¯å¾„
    dataset_files = {
        'train': '../../../datasets/{}/bert_train.json'.format(opt.dataset),
        'test': '../../../datasets/{}/bert_test.json'.format(opt.dataset),
        'val': '../../../datasets/{}/bert_dev.json'.format(opt.dataset)
    }
    
    #å®šä¹‰å‚æ•°åˆå§‹åŒ–çš„æ–¹æ³•
    initializers = {
        'xavier_uniform_': torch.nn.init.xavier_uniform_,
        'xavier_normal_': torch.nn.init.xavier_normal,
        'orthogonal_': torch.nn.init.orthogonal_,
    }


    #è®¾ç½®é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„å’Œå…¶ä»–å‚æ•°
    logger.info(opt.pretrained_model)        #PLM---bart-base/bart-large/roberta-base/roberta-large
    opt.dataset_file = dataset_files
    opt.inputs_cols = ['text_bert_indices', 'input_mask', 'label']    #é…ç½®æ¨¡å‹è¾“å…¥åˆ—å
    opt.initializer = initializers[opt.initializer] 
    opt.device = torch.device(opt.device if torch.cuda.is_available() else 'cpu') 

    ins = Instructor(opt)   #åˆ›å»ºInstructorå®ä¾‹å¹¶æ‰§è¡Œè¯„ä¼°
    ins.run()


if __name__ == '__main__':
    main()
